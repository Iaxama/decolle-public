Nhid: []
Mhid: 
- 1000
- 1000
- 1000
alpha:
- 0.97
alpharp:
- 0.65
batch_size: 288
beta:
- 0.92
betas:
- 0.0
- 0.95
burnin_steps: 100
chunk_size_test: 1000
chunk_size_train: 1000
dataset: pytorch_datasets.ntidigits.ntidigits_dataloaders
deltat: 1000
error_rate: 1.e-2
init_theta: 
- 1.e-06
- 1.e-06
- 1.e-06
input_shape:
- 64
- 1
- 1
kernel_size:
- 7
lc_ampl: 0.5
learning_rate: .4e-09
loss: smoothL1 #Not used
lr_drop_factor: 2
lr_drop_interval: 100
num_epochs: 300
num_conv_layers: 0
num_mlp_layers: 3
num_layers: 3
optimizer: adamax #Not used
out_channels: 11
pool_size:
- 2
- 1
- 2
reg_l:
- .0
- .0
- .0
- .0
test_interval: 1
